{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_0KT3fbNacSw",
        "g-GdxqKtvzA8",
        "u-M-lgWaZGPv"
      ],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas lxml tqdm dicttoxml"
      ],
      "metadata": {
        "id": "Xa466M5z8GZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mapeo de Metadatos"
      ],
      "metadata": {
        "id": "RujzfIoVwRJS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uRufs7b7JaM"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "ETL: InBio ➜ Plinian Core 3.2 mapper\n",
        "-----------------------------------\n",
        "✓ Python >= 3.9\n",
        "✓ pip install pandas lxml tqdm dicttoxml\n",
        "\n",
        "Usage:\n",
        "    python inbio_to_plinian.py reg_especies_INBiov5.csv\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import pandas as pd\n",
        "from dicttoxml import dicttoxml\n",
        "from lxml import etree\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 1 │ CONFIGURATION\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "#: map each description_type (lower-case, trimmed) to\n",
        "#: (Plinian element, Plinian sub-element OR None if simple element)\n",
        "DESCRIPTION_MAP: Dict[str, Tuple[str, str | None]] = {\n",
        "    \"common_names\": (\"CommonNames\", \"commonName\"),\n",
        "    \"synonyms\": (\"Synonyms\", \"synonym\"),\n",
        "    \"cr_distribution\": (\"Distribution\", \"distributionArea\"),\n",
        "    \"regional_distribution\": (\"Distribution\", \"distributionArea\"),\n",
        "    \"annual_cycles\": (\"AnnualCycles\", \"annualCycle\"),\n",
        "    \"phenology\": (\"AnnualCycles\", \"phenology\"),\n",
        "    \"behavior\": (\"Behavior\", None),\n",
        "    \"feeding\": (\"Feeding\", None),\n",
        "    \"habitat\": (\"Habitats\", \"habitatDescription\"),\n",
        "    \"interaction\": (\"Interaction\", None),\n",
        "    \"life_cycle\": (\"LifeCycle\", None),\n",
        "    \"life_form\": (\"LifeForm\", None),\n",
        "    \"population_biology\": (\"PopulationBiology\", None),\n",
        "    \"demography\": (\"DemographyAndThreat\", \"demography\"),\n",
        "    \"threat\": (\"ThreatStatus\", None),\n",
        "    \"reproduction\": (\"Reproduction\", None),\n",
        "    \"territory\": (\"Territory\", None),\n",
        "    \"uses\": (\"Uses\", None),\n",
        "    \"conservation_area_distribution\": (\n",
        "        \"ManagementAndConservation\",\n",
        "        \"conservationAreas\",\n",
        "    ),\n",
        "    \"wild_protected_area\": (\n",
        "        \"ManagementAndConservation\",\n",
        "        \"wildProtectedAreas\",\n",
        "    ),\n",
        "    \"collecting_method\": (\n",
        "        \"IdentificationKeys\",\n",
        "        \"collectingMethod\",\n",
        "    ),  # extension field\n",
        "    \"full_description\": (\"TaxonomicDescription\", None),\n",
        "    \"myths\": (\n",
        "        \"Notes\",\n",
        "        None,\n",
        "    ),\n",
        "}\n",
        "\n",
        "UNMAPPED_BUCKET = \"Notes\"\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 2 │ HELPERS\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "def add_value(rec: dict, element: str, subelement: str | None, value: str) -> None:\n",
        "    \"\"\"Safely append *value* under rec[element][subelement].\"\"\"\n",
        "    if subelement is None:  # simple element = list of strings\n",
        "        rec.setdefault(element, [])\n",
        "        if value not in rec[element]:\n",
        "            rec[element].append(value)\n",
        "    else:  # nested dict with its own list\n",
        "        node = rec.setdefault(element, {})\n",
        "        node.setdefault(subelement, [])\n",
        "        if value not in node[subelement]:\n",
        "            node[subelement].append(value)\n",
        "\n",
        "\n",
        "def build_plinian_record(group: pd.DataFrame) -> dict:\n",
        "    \"\"\"Convert *one* taxon’s rows into a nested Plinian Core record.\"\"\"\n",
        "    # Pull master (scalar) fields out of the first row\n",
        "    first = group.iloc[0]\n",
        "    record: dict = {\n",
        "        \"identifier\": str(int(first[\"taxon_record_id\"])),\n",
        "        \"NomenclatureAndClassification\": {\n",
        "            \"kingdom\": str(first[\"kingdom\"]).capitalize().strip(),\n",
        "            \"scientificName\": first[\"default_name\"].strip(),\n",
        "        },\n",
        "    }\n",
        "\n",
        "    # Walk through every row that contains a description blob\n",
        "    for _, row in group.iterrows():\n",
        "        text = str(row[\"description\"]).strip()\n",
        "        if not text:\n",
        "            continue\n",
        "        desc_type = str(row[\"description_type\"]).strip().lower()\n",
        "        element, subelement = DESCRIPTION_MAP.get(desc_type, (UNMAPPED_BUCKET, None))\n",
        "        add_value(record, element, subelement, text)\n",
        "\n",
        "    return record\n",
        "\n",
        "\n",
        "def dict_to_pretty_xml(d: dict) -> bytes:\n",
        "    \"\"\"dict ➜ XML (pretty)\"\"\"\n",
        "    # dicttoxml puts the root tag <root>; we rename to <PlinianRecord>\n",
        "    raw = dicttoxml(\n",
        "        d,\n",
        "        attr_type=False,\n",
        "        custom_root=\"PlinianRecord\",\n",
        "        item_func=lambda _: \"item\",\n",
        "    )\n",
        "    tree = etree.fromstring(raw)\n",
        "    return etree.tostring(\n",
        "        tree,\n",
        "        pretty_print=True,\n",
        "        xml_declaration=True,\n",
        "        encoding=\"UTF-8\",\n",
        "    )\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 3 │ MAIN PIPELINE\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "def main(csv_path: str | Path) -> None:\n",
        "    csv_path = Path(csv_path)\n",
        "    if not csv_path.is_file():\n",
        "        sys.exit(f\"ERROR: Cannot find {csv_path}\")\n",
        "\n",
        "    out_jsonl = csv_path.with_name(\"plinian_records.jsonl\")\n",
        "    out_xml_dir = csv_path.with_name(\"out_xml\")\n",
        "    out_xml_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # --- load & clean\n",
        "    df = pd.read_csv(csv_path, sep=\"|\")\n",
        "    df[\"description_type\"] = df[\"description_type\"].str.strip().str.lower()\n",
        "\n",
        "    # --- build records\n",
        "    records: List[dict] = []\n",
        "    with open(out_jsonl, \"w\", encoding=\"utf-8\") as jf:\n",
        "        for taxon_id, group in tqdm(\n",
        "            df.groupby(\"taxon_record_id\", sort=False),\n",
        "            desc=\"Building Plinian records\",\n",
        "        ):\n",
        "            rec = build_plinian_record(group)\n",
        "            records.append(rec)\n",
        "\n",
        "            # write JSON Lines\n",
        "            jf.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "            # write XML\n",
        "            xml_bytes = dict_to_pretty_xml(rec)\n",
        "            xml_path = out_xml_dir / f\"{int(taxon_id)}.xml\"\n",
        "            xml_path.write_bytes(xml_bytes)\n",
        "\n",
        "    print(f\"\\n✅  Wrote {len(records):,} JSON records to:  {out_jsonl}\")\n",
        "    print(f\"✅  Wrote XML files to:               {out_xml_dir.absolute()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = \"/content/reg_especies_INBiov5.csv\"\n",
        "main(csv_path)"
      ],
      "metadata": {
        "id": "WAmH5ujVBHTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Consulta sencilla\n"
      ],
      "metadata": {
        "id": "_0KT3fbNacSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pymilvus import connections, Collection\n",
        "\n",
        "# Cambia la IP/puerto si usas otros\n",
        "connections.connect(\"default\", host=MILVUS_HOST, port=MILVUS_PORT)\n",
        "\n",
        "colec = Collection(\"inbio_plinian_qa\")   # nombre que usamos en la ingesta\n",
        "colec.load()                             # carga los índices en memoria\n",
        "\n",
        "print(\"Nº total de registros:\", colec.num_entities)        # cuántas P-R hay\n",
        "print(\"Esquema:\\n\", colec.schema)                          # campos y tipos\n"
      ],
      "metadata": {
        "id": "z6sAVu8dafWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Milvus permite consultar con expresiones lógicas\n",
        "docs = colec.query(\n",
        "    expr=\"kingdom == 'Plantae'\",                       # sin filtro: devuelve los primeros que encuentre\n",
        "    limit=5,\n",
        "    output_fields=[\n",
        "        \"qa_id\", \"question\", \"answer\",\n",
        "        \"taxon_id\", \"kingdom\", \"threat_status\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "for d in docs:\n",
        "    print(f\"[{d['qa_id']}] P: {d['question']}\\n    R: {d['answer']}\\n---\")"
      ],
      "metadata": {
        "id": "qELnc7sQbFRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "def embed(txt):\n",
        "    return encoder.encode([txt], normalize_embeddings=True).tolist()[0]\n",
        "\n",
        "# ---- consulta de ejemplo ----\n",
        "consulta = \"hábitat de Ateles geoffroyi\"\n",
        "vec = embed(consulta)\n",
        "\n",
        "res = colec.search(\n",
        "    data=[vec],\n",
        "    anns_field=\"embedding\",\n",
        "    param={\"nprobe\": 32},\n",
        "    limit=3,\n",
        "    expr=\"kingdom == 'Animalia'\",\n",
        "    output_fields=[\"question\", \"answer\", \"taxon_id\"]\n",
        ")\n",
        "\n",
        "for hit in res[0]:\n",
        "    print(f\"score={hit.distance:.3f}\")\n",
        "    print(\"P:\", hit.entity.question)\n",
        "    print(\"R:\", hit.entity.answer, \"\\n---\")\n"
      ],
      "metadata": {
        "id": "dRoF4DyZbm2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ingesta a Milvus con los datos del InBio\n",
        "## Se hacen preguntas quemadas generadas automaticamente por cada uno de los metadatos para llenar la coleccion de prueba en Milvus añojada en Azure\n",
        "\n"
      ],
      "metadata": {
        "id": "g-GdxqKtvzA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymilvus"
      ],
      "metadata": {
        "id": "scL6rXzJ-eGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Ingerir registros Plinian en Milvus con etiqueta plinian_field\n",
        "-------------------------------------------------------------\n",
        "• pip install pymilvus==2.4.3 pandas sentence-transformers tqdm torch>=2.0\n",
        "\"\"\"\n",
        "\n",
        "import json, os, re, random\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from pymilvus import (\n",
        "    connections, Collection, FieldSchema, CollectionSchema, DataType, utility\n",
        ")\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "\n",
        "# ───────────────────────── CONFIGURACION PARA ACCEDER A VM AZURE y OTROS ─────────────────────────\n",
        "CSV_PATH         = Path(\"reg_especies_INBiov5.csv\")\n",
        "MILVUS_HOST      = \"135.237.82.231\"\n",
        "MILVUS_PORT      = \"19530\"\n",
        "COLLECTION_NAME  = \"inbio_plinian_qa\"\n",
        "HF_MODEL         = \"embaas/sentence-transformers-multilingual-e5-base\"   # 768 d\n",
        "DIM              = 768\n",
        "BATCH            = 128\n",
        "SEED             = 42\n",
        "# ──────────────────────────────────────────────────────────────────\n",
        "\n",
        "\n",
        "# -------------------- Plantillas por campo Plinian ----------------\n",
        "# Para cada elemento Plinian define AL MENOS una plantilla de pregunta\n",
        "TEMPLATES_PLI = {\n",
        "    \"NomenclatureAndClassification\": [\n",
        "        \"¿Cuál es el nombre científico de la especie {sci}?\",\n",
        "        \"¿A qué reino pertenece {sci}?\"\n",
        "    ],\n",
        "    \"CommonNames\": [\n",
        "        \"¿Cuáles son los nombres comunes de {sci}?\"\n",
        "    ],\n",
        "    \"Habitats\": [\n",
        "        \"¿En qué hábitats se encuentra {sci}?\"\n",
        "    ],\n",
        "    \"ThreatStatus\": [\n",
        "        \"¿Cuál es el estado de amenaza (UICN) de {sci}?\"\n",
        "    ],\n",
        "    \"AnnualCycles\": [\n",
        "        \"¿Cómo es la fenología anual de {sci}?\"\n",
        "    ],\n",
        "    \"Behavior\": [\n",
        "        \"¿Cuál es el comportamiento típico de {sci}?\"\n",
        "    ],\n",
        "    \"Feeding\": [\n",
        "        \"¿De qué se alimenta {sci}?\"\n",
        "    ],\n",
        "    \"Interaction\": [\n",
        "        \"¿Con qué otras especies interactúa {sci}?\"\n",
        "    ],\n",
        "    \"LifeCycle\": [\n",
        "        \"Describe el ciclo de vida de {sci}.\"\n",
        "    ],\n",
        "    \"LifeForm\": [\n",
        "        \"¿Qué forma de vida presenta {sci}?\"\n",
        "    ],\n",
        "    \"PopulationBiology\": [\n",
        "        \"¿Qué se sabe de la biología poblacional de {sci}?\"\n",
        "    ],\n",
        "    \"Reproduction\": [\n",
        "        \"¿Cómo se reproduce {sci}?\"\n",
        "    ],\n",
        "    \"Uses\": [\n",
        "        \"¿Qué usos se le atribuyen a {sci}?\"\n",
        "    ],\n",
        "    \"Distribution\": [\n",
        "        \"¿Dónde se distribuye {sci}?\"\n",
        "    ],\n",
        "    \"DemographyAndThreat\": [\n",
        "        \"¿Cuáles son los aspectos demográficos y de amenaza de {sci}?\"\n",
        "    ],\n",
        "    \"TaxonomicDescription\": [\n",
        "        \"Proporcione una descripción taxonómica de {sci}.\"\n",
        "    ],\n",
        "    \"Synonyms\": [\n",
        "        \"¿Qué sinónimos taxonómicos tiene {sci}?\"\n",
        "    ],\n",
        "    \"Territory\": [\n",
        "        \"¿Cuál es el territorio característico de {sci}?\"\n",
        "    ],\n",
        "    \"Dispersal\": [\n",
        "        \"¿Cómo se dispersa {sci}?\"\n",
        "    ],\n",
        "    \"EcologicalSignificance\": [\n",
        "        \"¿Cuál es la importancia ecológica de {sci}?\"\n",
        "    ],\n",
        "    \"ManagementAndConservation\": [\n",
        "        \"¿Qué acciones de manejo y conservación existen para {sci}?\"\n",
        "    ],\n",
        "    \"Migratory\": [\n",
        "        \"¿{sci} presenta comportamientos migratorios?\",\n",
        "        \"Describa el patrón migratorio de {sci}.\"\n",
        "    ],\n",
        "    \"MolecularData\": [\n",
        "        \"¿Qué información molecular se conoce de {sci} (por ejemplo, secuencias de ADN o proteínas)?\"\n",
        "    ],\n",
        "    \"IdentificationKeys\": [\n",
        "        \"¿Existe una clave de identificación para {sci}?\",\n",
        "        \"¿Cómo se puede identificar {sci} mediante claves taxonómicas?\"\n",
        "    ],\n",
        "    \"Invasiveness\": [\n",
        "        \"¿{sci} es considerada una especie invasora?\"\n",
        "    ],\n",
        "    \"Legislation\": [\n",
        "        \"¿Qué legislación protege o regula a {sci}?\",\n",
        "        \"Mencione leyes o normativas relacionadas con {sci}.\"\n",
        "    ],\n",
        "    \"Endemic\": [\n",
        "        \"¿{sci} es endémica de alguna región?\",\n",
        "        \"Indique las áreas donde {sci} es endémica.\"\n",
        "    ],\n",
        "    \"EnvironmentalEnvelope\": [\n",
        "        \"¿Cuál es el rango ambiental (precipitación, temperatura, etc.) donde vive {sci}?\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "\n",
        "# Campos del CSV que mapean directamente a los nombres Plinian usados\n",
        "CSV_TO_PLI = {\n",
        "    \"common_names\":            \"CommonNames\",\n",
        "    \"habitat\":                 \"Habitats\",\n",
        "    \"threat\":                  \"ThreatStatus\",\n",
        "    \"annual_cycles\":           \"AnnualCycles\",\n",
        "    \"phenology\":               \"AnnualCycles\",\n",
        "    \"behavior\":                \"Behavior\",\n",
        "    \"feeding\":                 \"Feeding\",\n",
        "    \"interaction\":             \"Interaction\",\n",
        "    \"life_cycle\":              \"LifeCycle\",\n",
        "    \"life_form\":               \"LifeForm\",\n",
        "    \"population_biology\":      \"PopulationBiology\",\n",
        "    \"reproduction\":            \"Reproduction\",\n",
        "    \"uses\":                    \"Uses\",\n",
        "    \"cr_distribution\":         \"Distribution\",\n",
        "    \"regional_distribution\":   \"Distribution\",\n",
        "    \"demography\":              \"DemographyAndThreat\",\n",
        "    \"synonyms\":                \"Synonyms\",\n",
        "    \"territory\":               \"Territory\",\n",
        "}\n",
        "\n",
        "\n",
        "# ------------------------ Limpieza básica -------------------------\n",
        "def clean_text(s: str) -> str:\n",
        "    return re.sub(r\"\\s+\", \" \", str(s)).strip()\n",
        "\n",
        "\n",
        "# ----------------- Construcción de DataFrames --------------------\n",
        "def build_dataframes(csv_path: Path) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    df = pd.read_csv(csv_path, sep=\"|\")\n",
        "\n",
        "    df = (\n",
        "        df.assign(kingdom=lambda d: d[\"kingdom\"].str.title(),\n",
        "                  description=lambda d: d[\"description\"].apply(clean_text),\n",
        "                  description_type=lambda d: d[\"description_type\"].str.strip())\n",
        "          .drop_duplicates(subset=[\"taxon_record_id\", \"description_type\", \"description\"])\n",
        "    )\n",
        "\n",
        "    pivot = (\n",
        "    df.pivot_table(index=\"default_name\",\n",
        "                   columns=\"description_type\",\n",
        "                   values=\"description\",\n",
        "                   aggfunc=\" \".join)\n",
        "      .reset_index()\n",
        "    )\n",
        "    basics = (\n",
        "        df[[\"default_name\", \"kingdom\"]]\n",
        "        .drop_duplicates()\n",
        "    )\n",
        "    wide = basics.merge(pivot, on=\"default_name\", how=\"left\")\n",
        "\n",
        "    qa_rows = []\n",
        "    random.seed(SEED)\n",
        "\n",
        "    for _, row in wide.iterrows():\n",
        "        sci    = row[\"default_name\"]\n",
        "        kingdom= row[\"kingdom\"]\n",
        "\n",
        "        # 1. armar diccionario con todos los posibles reemplazos\n",
        "        subs = {\"sci\": sci, \"kingdom\": kingdom }\n",
        "        for csv_field in CSV_TO_PLI.keys():\n",
        "            subs[csv_field] = row.get(csv_field, \"\")\n",
        "\n",
        "        # 2. para cada campo Plinian presente, crear preguntas\n",
        "        for csv_field, plinian_field in CSV_TO_PLI.items():\n",
        "            if pd.isna(row.get(csv_field)):        # no hay dato\n",
        "                continue\n",
        "            texto_resp = row[csv_field]\n",
        "            for plantilla in TEMPLATES_PLI.get(plinian_field, []):\n",
        "                qa_rows.append({\n",
        "                    \"question\": plantilla.format(**subs).strip(),\n",
        "                    \"answer\": clean_text(texto_resp),\n",
        "                    \"plinian_field\": plinian_field,\n",
        "                    \"scientific_name\": sci,\n",
        "                    \"kingdom\": kingdom\n",
        "                })\n",
        "\n",
        "        # 3. añadir también preguntas básicos siempre presentes\n",
        "        for plantilla in TEMPLATES_PLI[\"NomenclatureAndClassification\"]:\n",
        "            ans = sci if \"nombre científico\" in plantilla else kingdom\n",
        "            qa_rows.append({\n",
        "                \"question\": plantilla.format(**subs).strip(),\n",
        "                \"answer\": ans,\n",
        "                \"plinian_field\": \"NomenclatureAndClassification\",\n",
        "                \"scientific_name\": sci,\n",
        "                \"kingdom\": kingdom\n",
        "            })\n",
        "\n",
        "    docs_df = wide.rename(columns={\"taxon_record_id\": \"taxon_id\"})\n",
        "    qa_df   = pd.DataFrame(qa_rows)\n",
        "    return docs_df, qa_df\n",
        "\n",
        "\n",
        "# ----------------------- Encoder de embeddings -------------------\n",
        "encoder = SentenceTransformer(HF_MODEL)\n",
        "def embed(textos: List[str]) -> List[List[float]]:\n",
        "    return encoder.encode(textos, normalize_embeddings=True).tolist()\n",
        "\n",
        "\n",
        "# -------------------- Crear colección en Milvus ------------------\n",
        "connections.connect(host=MILVUS_HOST, port=MILVUS_PORT, alias=\"default\")\n",
        "\n",
        "if utility.has_collection(COLLECTION_NAME):\n",
        "    collection = Collection(COLLECTION_NAME)\n",
        "else:\n",
        "    schema = CollectionSchema([\n",
        "        FieldSchema(\"qa_id\", DataType.INT64, is_primary=True, auto_id=True),\n",
        "        FieldSchema(\"embedding\", DataType.FLOAT_VECTOR, dim=DIM),\n",
        "        FieldSchema(\"question\", DataType.VARCHAR, max_length=512),\n",
        "        FieldSchema(\"answer\",   DataType.VARCHAR, max_length=8192),\n",
        "        FieldSchema(\"plinian_field\", DataType.VARCHAR, max_length=64),\n",
        "        FieldSchema(\"scientific_name\", DataType.VARCHAR, max_length=128),\n",
        "        FieldSchema(\"kingdom\",         DataType.VARCHAR, max_length=32),\n",
        "    ], description=\"P-R etiquetados con elemento Plinian\")\n",
        "    collection = Collection(COLLECTION_NAME, schema, consistency_level=\"Strong\")\n",
        "    collection.create_index(\"embedding\", {\n",
        "        \"index_type\": \"IVF_FLAT\",\n",
        "        \"metric_type\": \"COSINE\",\n",
        "        \"params\": {\"nlist\": 2048}\n",
        "    })\n",
        "\n",
        "# --------------------------- Ingesta ------------------------------\n",
        "docs_df, qa_df = build_dataframes(CSV_PATH)\n",
        "\n",
        "print(f\"Especies leídas:  {docs_df.shape[0]:,}\")\n",
        "print(f\"P-R generadas:   {qa_df.shape[0]:,}\")\n",
        "\n",
        "# Inserción por lotes\n",
        "batch_q, batch_a, batch_emb, batch_f, batch_sci, batch_king = ([] for _ in range(6))\n",
        "\n",
        "for _, fila in tqdm(qa_df.iterrows(), total=len(qa_df), desc=\"Insertando\"):\n",
        "    batch_q.append(fila[\"question\"])\n",
        "    batch_a.append(fila[\"answer\"])\n",
        "    batch_f.append(fila[\"plinian_field\"])\n",
        "    batch_sci.append(fila[\"scientific_name\"])\n",
        "    batch_king.append(fila[\"kingdom\"])\n",
        "\n",
        "    if len(batch_q) == BATCH:\n",
        "        collection.insert([\n",
        "            embed(batch_q), batch_q, batch_a,\n",
        "            batch_f, batch_sci, batch_king\n",
        "        ])\n",
        "        batch_q, batch_a, batch_f, batch_sci, batch_king = ([] for _ in range(5))\n",
        "\n",
        "# inserta lo restante\n",
        "if batch_q:\n",
        "    collection.insert([\n",
        "        embed(batch_q), batch_q, batch_a,\n",
        "        batch_f, batch_sci, batch_king\n",
        "    ])\n",
        "\n",
        "collection.flush()\n",
        "print(\"✅  Ingesta completada en Milvus\")\n"
      ],
      "metadata": {
        "id": "B1fvpdjyvyjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exploracion Metadatos InBio"
      ],
      "metadata": {
        "id": "u-M-lgWaZGPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Explora los metadatos presentes en reg_especies_INBiov5.csv\n",
        "-----------------------------------------------------------\n",
        "• pip install pandas\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "CSV_PATH = Path(\"reg_especies_INBiov5.csv\")\n",
        "SEP      = \"|\"                                # delimitador vertical\n",
        "\n",
        "# 1) Lee una pequeña porción para ver las columnas\n",
        "preview = pd.read_csv(CSV_PATH, sep=SEP, nrows=5)\n",
        "print(\"Columnas del CSV:\")\n",
        "for c in preview.columns:\n",
        "    print(\"  •\", c)\n",
        "\n",
        "types_series = pd.read_csv(\n",
        "    CSV_PATH,\n",
        "    sep=SEP,\n",
        "    usecols=[\"description_type\"]\n",
        ")[\"description_type\"].astype(str).str.strip()\n",
        "\n",
        "# 3) Obtiene lista única y ordenada\n",
        "unique_types = sorted(types_series.unique())\n",
        "print(\"\\nMetadatos temáticos (description_type) encontrados:\")\n",
        "for t in unique_types:\n",
        "    print(\"  •\", t)\n",
        "\n",
        "# 4) Conteo de registros por tipo\n",
        "counts = types_series.value_counts().sort_values(ascending=False)\n",
        "print(\"\\nConteo de filas por metadato:\")\n",
        "for t, n in counts.items():\n",
        "    print(f\"  • {t:<35} {n:>6}\")\n"
      ],
      "metadata": {
        "id": "y9k1zeCGv61b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RAG"
      ],
      "metadata": {
        "id": "1uzxw97RY4nT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade sentence-transformers pymilvus transformers ipywidgets huggingface-hub --quiet"
      ],
      "metadata": {
        "id": "OGrf-gZhagrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q ipywidgets\n",
        "!jupyter nbextension enable --py widgetsnbextension\n",
        "!jupyter nbextension enable --py --sys-prefix widgetsnbextension"
      ],
      "metadata": {
        "id": "R6JVl2uZcDN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(\"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\")"
      ],
      "metadata": {
        "id": "NAKcqobgblVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ────────── 0 · Instalación de dependencias ──────────\n",
        "!pip install gradio==4.29.0 pymilvus sentence-transformers transformers accelerate bitsandbytes --quiet\n",
        "\n",
        "# ────────── 1 · Imports y Configuración ──────────\n",
        "import os, re, torch\n",
        "from typing import List, Dict\n",
        "\n",
        "import gradio as gr\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pymilvus import MilvusClient, Collection, connections\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TextIteratorStreamer\n",
        "\n",
        "# Milvus\n",
        "MILVUS_HOST = \"135.237.82.231\"\n",
        "MILVUS_PORT = \"19530\"\n",
        "COLLECTION  = \"inbio_plinian_qa\"\n",
        "VEC_FIELD   = \"embedding\"\n",
        "OUT_FIELDS  = [\"answer\", \"scientific_name\", \"plinian_field\"]\n",
        "\n",
        "# Modelos\n",
        "EMBED_MODEL = \"embaas/sentence-transformers-multilingual-e5-base\"   # 384 d\n",
        "LLM_ID      = \"NousResearch/Nous-Hermes-2-Mistral-7B-DPO\"          # abierto\n",
        "DEVICE      = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Busca top-k contextos; configurable desde la UI\n",
        "DEFAULT_K   = 5\n",
        "\n",
        "# ────────── 2 · Cargar embedder y LLM ──────────\n",
        "embedder = SentenceTransformer(EMBED_MODEL, device=DEVICE)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(LLM_ID)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    LLM_ID,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16,\n",
        "    #load_in_4bit=True\n",
        ")\n",
        "\n",
        "# ────────── 3 · Cliente Milvus ──────────\n",
        "print(f\"🔹 Conectando a Milvus {MILVUS_HOST}:{MILVUS_PORT}…\")\n",
        "client = MilvusClient(uri=f\"tcp://{MILVUS_HOST}:{MILVUS_PORT}\")\n",
        "client.load_collection(COLLECTION)\n",
        "print(\"   ok\\n\")\n",
        "\n",
        "# ────────── 4 · Funciones auxiliares ──────────\n",
        "def detect_field(question:str)->str|None:\n",
        "    \"\"\"Clasificador placeholder (devuelve None = sin filtro).\"\"\"\n",
        "    q = question.lower()\n",
        "    if \"hábitat\" in q: return \"Habitats\"\n",
        "    if \"amenaz\"  in q or \"uicn\" in q: return \"ThreatStatus\"\n",
        "    return None\n",
        "\n",
        "def build_prompt(question: str, hits: List[Dict]) -> str:\n",
        "    \"\"\"\n",
        "    Crea un prompt limpio para el LLM.\n",
        "    Cada hit es un dict que trae:\n",
        "        • hit['distance']          (float)\n",
        "        • hit['entity']['answer']  (str)\n",
        "        • hit['entity']['scientific_name']\n",
        "        • hit['entity']['plinian_field']\n",
        "    \"\"\"\n",
        "    # armamos bloques numerados con las 3-5 evidencias\n",
        "    bloques = []\n",
        "    for i, hit in enumerate(hits, 1):\n",
        "        ent = hit[\"entity\"]\n",
        "        dist = hit[\"distance\"]\n",
        "        breve = ent[\"answer\"]\n",
        "        bloques.append(\n",
        "            f\"[{i}] {ent['scientific_name']} · {ent['plinian_field']} \"\n",
        "            f\"(sim={1-dist:.3f}): {breve}\"\n",
        "        )\n",
        "\n",
        "    contexto = \"\\n\\n\".join(bloques)\n",
        "\n",
        "    prompt = (\n",
        "        \"Sistema: Eres un redactor experto en biodiversidad de Costa Rica. \"\n",
        "        \"Usa el contexto para responder en **un párrafos** bien redactados, \"\n",
        "        \"en español, explicando el dato y añadiendo detalles relevantes del contexto. \"\n",
        "        f\"### CONTEXTO\\n{contexto}\\n\\n\"\n",
        "        f\"### PREGUNTA\\n{question}\\n\\n\"\n",
        "        \"### RESPUESTA (dos párrafos):\"\n",
        "    )\n",
        "    return prompt\n",
        "\n",
        "# ────────── 5 · Función principal para Gradio ──────────\n",
        "def rag_answer(msg: str, k: int = DEFAULT_K, temperatura: float = 0.0):\n",
        "    # 1) embedding\n",
        "    q_vec = embedder.encode([msg], normalize_embeddings=True)[0]\n",
        "\n",
        "    # 2) búsqueda vectorial  (sin filtro por ahora)-> Por ahora no implementamos filtros, con milvus es muy facil y diverso\n",
        "    hits = client.search(\n",
        "        collection_name=COLLECTION,\n",
        "        data=[q_vec],\n",
        "        limit=k,\n",
        "        output_fields=OUT_FIELDS,\n",
        "        search_params={\"metric_type\": \"COSINE\", \"params\": {\"nprobe\": 10}}\n",
        "    )[0]\n",
        "    if not hits:\n",
        "        return \"No encontré información suficiente para responder.\"\n",
        "\n",
        "    # 3) prompt\n",
        "    prompt = build_prompt(msg, hits)\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    # 4) generación bloqueante (más tokens para evitar corte)\n",
        "    out = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=256,\n",
        "        do_sample=temperatura > 0,\n",
        "        temperature=float(temperatura),\n",
        "        top_p=0.95,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    respuesta = tokenizer.decode(\n",
        "        out[0][inputs[\"input_ids\"].shape[-1]:],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "    return respuesta.strip()\n",
        "\n",
        "# ────────── 6 · Construir interfaz Gradio ──────────\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"## 🌿 **Biodiversidad Costa Rica – RAG**\")\n",
        "\n",
        "    chat = gr.Chatbot(height=400)\n",
        "    with gr.Row():\n",
        "        txt = gr.Textbox(\n",
        "            scale=4,\n",
        "            placeholder=\"Pregunta sobre una especie, su hábitat, amenazas, etc.\"\n",
        "        )\n",
        "        enviar = gr.Button(\"Enviar\", scale=1)\n",
        "\n",
        "    with gr.Row():\n",
        "        k_slider = gr.Slider(1,10,value=DEFAULT_K,step=1,label=\"Top-k documentos\")\n",
        "        temp = gr.Slider(0,1,value=0.0,step=0.05,label=\"Creatividad (temperature)\")\n",
        "\n",
        "    def user(user_message, history):\n",
        "        return \"\", history + [[user_message, None]]\n",
        "\n",
        "    def bot(history, k, temperatura):\n",
        "        user_message = history[-1][0]\n",
        "        respuesta = rag_answer(user_message, k=int(k), temperatura=float(temperatura))\n",
        "        history[-1][1] = respuesta\n",
        "        return history\n",
        "\n",
        "    txt.submit(user, [txt, chat], [txt, chat]).then(\n",
        "        bot, [chat, k_slider, temp], chat\n",
        "    )\n",
        "    enviar.click(user, [txt, chat], [txt, chat]).then(\n",
        "        bot, [chat, k_slider, temp], chat\n",
        "    )\n",
        "\n",
        "# ────────── 7 · Lanzar servidor ──────────\n",
        "demo.launch(share=True, debug=True) #da una url publica\n"
      ],
      "metadata": {
        "id": "2Glnr5K-eqAm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}