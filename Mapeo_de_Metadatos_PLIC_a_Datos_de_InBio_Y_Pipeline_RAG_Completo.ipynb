{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_0KT3fbNacSw",
        "g-GdxqKtvzA8",
        "u-M-lgWaZGPv"
      ],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas lxml tqdm dicttoxml"
      ],
      "metadata": {
        "id": "Xa466M5z8GZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mapeo de Metadatos"
      ],
      "metadata": {
        "id": "RujzfIoVwRJS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uRufs7b7JaM"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "ETL: InBio âžœ Plinian Core 3.2 mapper\n",
        "-----------------------------------\n",
        "âœ“ Python >= 3.9\n",
        "âœ“ pip install pandas lxml tqdm dicttoxml\n",
        "\n",
        "Usage:\n",
        "    python inbio_to_plinian.py reg_especies_INBiov5.csv\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import pandas as pd\n",
        "from dicttoxml import dicttoxml\n",
        "from lxml import etree\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 1 â”‚ CONFIGURATION\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "#: map each description_type (lower-case, trimmed) to\n",
        "#: (Plinian element, Plinian sub-element OR None if simple element)\n",
        "DESCRIPTION_MAP: Dict[str, Tuple[str, str | None]] = {\n",
        "    \"common_names\": (\"CommonNames\", \"commonName\"),\n",
        "    \"synonyms\": (\"Synonyms\", \"synonym\"),\n",
        "    \"cr_distribution\": (\"Distribution\", \"distributionArea\"),\n",
        "    \"regional_distribution\": (\"Distribution\", \"distributionArea\"),\n",
        "    \"annual_cycles\": (\"AnnualCycles\", \"annualCycle\"),\n",
        "    \"phenology\": (\"AnnualCycles\", \"phenology\"),\n",
        "    \"behavior\": (\"Behavior\", None),\n",
        "    \"feeding\": (\"Feeding\", None),\n",
        "    \"habitat\": (\"Habitats\", \"habitatDescription\"),\n",
        "    \"interaction\": (\"Interaction\", None),\n",
        "    \"life_cycle\": (\"LifeCycle\", None),\n",
        "    \"life_form\": (\"LifeForm\", None),\n",
        "    \"population_biology\": (\"PopulationBiology\", None),\n",
        "    \"demography\": (\"DemographyAndThreat\", \"demography\"),\n",
        "    \"threat\": (\"ThreatStatus\", None),\n",
        "    \"reproduction\": (\"Reproduction\", None),\n",
        "    \"territory\": (\"Territory\", None),\n",
        "    \"uses\": (\"Uses\", None),\n",
        "    \"conservation_area_distribution\": (\n",
        "        \"ManagementAndConservation\",\n",
        "        \"conservationAreas\",\n",
        "    ),\n",
        "    \"wild_protected_area\": (\n",
        "        \"ManagementAndConservation\",\n",
        "        \"wildProtectedAreas\",\n",
        "    ),\n",
        "    \"collecting_method\": (\n",
        "        \"IdentificationKeys\",\n",
        "        \"collectingMethod\",\n",
        "    ),  # extension field\n",
        "    \"full_description\": (\"TaxonomicDescription\", None),\n",
        "    \"myths\": (\n",
        "        \"Notes\",\n",
        "        None,\n",
        "    ),\n",
        "}\n",
        "\n",
        "UNMAPPED_BUCKET = \"Notes\"\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 2 â”‚ HELPERS\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "def add_value(rec: dict, element: str, subelement: str | None, value: str) -> None:\n",
        "    \"\"\"Safely append *value* under rec[element][subelement].\"\"\"\n",
        "    if subelement is None:  # simple element = list of strings\n",
        "        rec.setdefault(element, [])\n",
        "        if value not in rec[element]:\n",
        "            rec[element].append(value)\n",
        "    else:  # nested dict with its own list\n",
        "        node = rec.setdefault(element, {})\n",
        "        node.setdefault(subelement, [])\n",
        "        if value not in node[subelement]:\n",
        "            node[subelement].append(value)\n",
        "\n",
        "\n",
        "def build_plinian_record(group: pd.DataFrame) -> dict:\n",
        "    \"\"\"Convert *one* taxonâ€™s rows into a nested Plinian Core record.\"\"\"\n",
        "    # Pull master (scalar) fields out of the first row\n",
        "    first = group.iloc[0]\n",
        "    record: dict = {\n",
        "        \"identifier\": str(int(first[\"taxon_record_id\"])),\n",
        "        \"NomenclatureAndClassification\": {\n",
        "            \"kingdom\": str(first[\"kingdom\"]).capitalize().strip(),\n",
        "            \"scientificName\": first[\"default_name\"].strip(),\n",
        "        },\n",
        "    }\n",
        "\n",
        "    # Walk through every row that contains a description blob\n",
        "    for _, row in group.iterrows():\n",
        "        text = str(row[\"description\"]).strip()\n",
        "        if not text:\n",
        "            continue\n",
        "        desc_type = str(row[\"description_type\"]).strip().lower()\n",
        "        element, subelement = DESCRIPTION_MAP.get(desc_type, (UNMAPPED_BUCKET, None))\n",
        "        add_value(record, element, subelement, text)\n",
        "\n",
        "    return record\n",
        "\n",
        "\n",
        "def dict_to_pretty_xml(d: dict) -> bytes:\n",
        "    \"\"\"dict âžœ XML (pretty)\"\"\"\n",
        "    # dicttoxml puts the root tag <root>; we rename to <PlinianRecord>\n",
        "    raw = dicttoxml(\n",
        "        d,\n",
        "        attr_type=False,\n",
        "        custom_root=\"PlinianRecord\",\n",
        "        item_func=lambda _: \"item\",\n",
        "    )\n",
        "    tree = etree.fromstring(raw)\n",
        "    return etree.tostring(\n",
        "        tree,\n",
        "        pretty_print=True,\n",
        "        xml_declaration=True,\n",
        "        encoding=\"UTF-8\",\n",
        "    )\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 3 â”‚ MAIN PIPELINE\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "def main(csv_path: str | Path) -> None:\n",
        "    csv_path = Path(csv_path)\n",
        "    if not csv_path.is_file():\n",
        "        sys.exit(f\"ERROR: Cannot find {csv_path}\")\n",
        "\n",
        "    out_jsonl = csv_path.with_name(\"plinian_records.jsonl\")\n",
        "    out_xml_dir = csv_path.with_name(\"out_xml\")\n",
        "    out_xml_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # --- load & clean\n",
        "    df = pd.read_csv(csv_path, sep=\"|\")\n",
        "    df[\"description_type\"] = df[\"description_type\"].str.strip().str.lower()\n",
        "\n",
        "    # --- build records\n",
        "    records: List[dict] = []\n",
        "    with open(out_jsonl, \"w\", encoding=\"utf-8\") as jf:\n",
        "        for taxon_id, group in tqdm(\n",
        "            df.groupby(\"taxon_record_id\", sort=False),\n",
        "            desc=\"Building Plinian records\",\n",
        "        ):\n",
        "            rec = build_plinian_record(group)\n",
        "            records.append(rec)\n",
        "\n",
        "            # write JSON Lines\n",
        "            jf.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "            # write XML\n",
        "            xml_bytes = dict_to_pretty_xml(rec)\n",
        "            xml_path = out_xml_dir / f\"{int(taxon_id)}.xml\"\n",
        "            xml_path.write_bytes(xml_bytes)\n",
        "\n",
        "    print(f\"\\nâœ…  Wrote {len(records):,} JSON records to:  {out_jsonl}\")\n",
        "    print(f\"âœ…  Wrote XML files to:               {out_xml_dir.absolute()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = \"/content/reg_especies_INBiov5.csv\"\n",
        "main(csv_path)"
      ],
      "metadata": {
        "id": "WAmH5ujVBHTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Consulta sencilla\n"
      ],
      "metadata": {
        "id": "_0KT3fbNacSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pymilvus import connections, Collection\n",
        "\n",
        "# Cambia la IP/puerto si usas otros\n",
        "connections.connect(\"default\", host=MILVUS_HOST, port=MILVUS_PORT)\n",
        "\n",
        "colec = Collection(\"inbio_plinian_qa\")   # nombre que usamos en la ingesta\n",
        "colec.load()                             # carga los Ã­ndices en memoria\n",
        "\n",
        "print(\"NÂº total de registros:\", colec.num_entities)        # cuÃ¡ntas P-R hay\n",
        "print(\"Esquema:\\n\", colec.schema)                          # campos y tipos\n"
      ],
      "metadata": {
        "id": "z6sAVu8dafWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Milvus permite consultar con expresiones lÃ³gicas\n",
        "docs = colec.query(\n",
        "    expr=\"kingdom == 'Plantae'\",                       # sin filtro: devuelve los primeros que encuentre\n",
        "    limit=5,\n",
        "    output_fields=[\n",
        "        \"qa_id\", \"question\", \"answer\",\n",
        "        \"taxon_id\", \"kingdom\", \"threat_status\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "for d in docs:\n",
        "    print(f\"[{d['qa_id']}] P: {d['question']}\\n    R: {d['answer']}\\n---\")"
      ],
      "metadata": {
        "id": "qELnc7sQbFRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "def embed(txt):\n",
        "    return encoder.encode([txt], normalize_embeddings=True).tolist()[0]\n",
        "\n",
        "# ---- consulta de ejemplo ----\n",
        "consulta = \"hÃ¡bitat de Ateles geoffroyi\"\n",
        "vec = embed(consulta)\n",
        "\n",
        "res = colec.search(\n",
        "    data=[vec],\n",
        "    anns_field=\"embedding\",\n",
        "    param={\"nprobe\": 32},\n",
        "    limit=3,\n",
        "    expr=\"kingdom == 'Animalia'\",\n",
        "    output_fields=[\"question\", \"answer\", \"taxon_id\"]\n",
        ")\n",
        "\n",
        "for hit in res[0]:\n",
        "    print(f\"score={hit.distance:.3f}\")\n",
        "    print(\"P:\", hit.entity.question)\n",
        "    print(\"R:\", hit.entity.answer, \"\\n---\")\n"
      ],
      "metadata": {
        "id": "dRoF4DyZbm2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ingesta a Milvus con los datos del InBio\n",
        "## Se hacen preguntas quemadas generadas automaticamente por cada uno de los metadatos para llenar la coleccion de prueba en Milvus aÃ±ojada en Azure\n",
        "\n"
      ],
      "metadata": {
        "id": "g-GdxqKtvzA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymilvus"
      ],
      "metadata": {
        "id": "scL6rXzJ-eGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Ingerir registros Plinian en Milvus con etiqueta plinian_field\n",
        "-------------------------------------------------------------\n",
        "â€¢ pip install pymilvus==2.4.3 pandas sentence-transformers tqdm torch>=2.0\n",
        "\"\"\"\n",
        "\n",
        "import json, os, re, random\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from pymilvus import (\n",
        "    connections, Collection, FieldSchema, CollectionSchema, DataType, utility\n",
        ")\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CONFIGURACION PARA ACCEDER A VM AZURE y OTROS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "CSV_PATH         = Path(\"reg_especies_INBiov5.csv\")\n",
        "MILVUS_HOST      = \"135.237.82.231\"\n",
        "MILVUS_PORT      = \"19530\"\n",
        "COLLECTION_NAME  = \"inbio_plinian_qa\"\n",
        "HF_MODEL         = \"embaas/sentence-transformers-multilingual-e5-base\"   # 768 d\n",
        "DIM              = 768\n",
        "BATCH            = 128\n",
        "SEED             = 42\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "\n",
        "# -------------------- Plantillas por campo Plinian ----------------\n",
        "# Para cada elemento Plinian define AL MENOS una plantilla de pregunta\n",
        "TEMPLATES_PLI = {\n",
        "    \"NomenclatureAndClassification\": [\n",
        "        \"Â¿CuÃ¡l es el nombre cientÃ­fico de la especie {sci}?\",\n",
        "        \"Â¿A quÃ© reino pertenece {sci}?\"\n",
        "    ],\n",
        "    \"CommonNames\": [\n",
        "        \"Â¿CuÃ¡les son los nombres comunes de {sci}?\"\n",
        "    ],\n",
        "    \"Habitats\": [\n",
        "        \"Â¿En quÃ© hÃ¡bitats se encuentra {sci}?\"\n",
        "    ],\n",
        "    \"ThreatStatus\": [\n",
        "        \"Â¿CuÃ¡l es el estado de amenaza (UICN) de {sci}?\"\n",
        "    ],\n",
        "    \"AnnualCycles\": [\n",
        "        \"Â¿CÃ³mo es la fenologÃ­a anual de {sci}?\"\n",
        "    ],\n",
        "    \"Behavior\": [\n",
        "        \"Â¿CuÃ¡l es el comportamiento tÃ­pico de {sci}?\"\n",
        "    ],\n",
        "    \"Feeding\": [\n",
        "        \"Â¿De quÃ© se alimenta {sci}?\"\n",
        "    ],\n",
        "    \"Interaction\": [\n",
        "        \"Â¿Con quÃ© otras especies interactÃºa {sci}?\"\n",
        "    ],\n",
        "    \"LifeCycle\": [\n",
        "        \"Describe el ciclo de vida de {sci}.\"\n",
        "    ],\n",
        "    \"LifeForm\": [\n",
        "        \"Â¿QuÃ© forma de vida presenta {sci}?\"\n",
        "    ],\n",
        "    \"PopulationBiology\": [\n",
        "        \"Â¿QuÃ© se sabe de la biologÃ­a poblacional de {sci}?\"\n",
        "    ],\n",
        "    \"Reproduction\": [\n",
        "        \"Â¿CÃ³mo se reproduce {sci}?\"\n",
        "    ],\n",
        "    \"Uses\": [\n",
        "        \"Â¿QuÃ© usos se le atribuyen a {sci}?\"\n",
        "    ],\n",
        "    \"Distribution\": [\n",
        "        \"Â¿DÃ³nde se distribuye {sci}?\"\n",
        "    ],\n",
        "    \"DemographyAndThreat\": [\n",
        "        \"Â¿CuÃ¡les son los aspectos demogrÃ¡ficos y de amenaza de {sci}?\"\n",
        "    ],\n",
        "    \"TaxonomicDescription\": [\n",
        "        \"Proporcione una descripciÃ³n taxonÃ³mica de {sci}.\"\n",
        "    ],\n",
        "    \"Synonyms\": [\n",
        "        \"Â¿QuÃ© sinÃ³nimos taxonÃ³micos tiene {sci}?\"\n",
        "    ],\n",
        "    \"Territory\": [\n",
        "        \"Â¿CuÃ¡l es el territorio caracterÃ­stico de {sci}?\"\n",
        "    ],\n",
        "    \"Dispersal\": [\n",
        "        \"Â¿CÃ³mo se dispersa {sci}?\"\n",
        "    ],\n",
        "    \"EcologicalSignificance\": [\n",
        "        \"Â¿CuÃ¡l es la importancia ecolÃ³gica de {sci}?\"\n",
        "    ],\n",
        "    \"ManagementAndConservation\": [\n",
        "        \"Â¿QuÃ© acciones de manejo y conservaciÃ³n existen para {sci}?\"\n",
        "    ],\n",
        "    \"Migratory\": [\n",
        "        \"Â¿{sci} presenta comportamientos migratorios?\",\n",
        "        \"Describa el patrÃ³n migratorio de {sci}.\"\n",
        "    ],\n",
        "    \"MolecularData\": [\n",
        "        \"Â¿QuÃ© informaciÃ³n molecular se conoce de {sci} (por ejemplo, secuencias de ADN o proteÃ­nas)?\"\n",
        "    ],\n",
        "    \"IdentificationKeys\": [\n",
        "        \"Â¿Existe una clave de identificaciÃ³n para {sci}?\",\n",
        "        \"Â¿CÃ³mo se puede identificar {sci} mediante claves taxonÃ³micas?\"\n",
        "    ],\n",
        "    \"Invasiveness\": [\n",
        "        \"Â¿{sci} es considerada una especie invasora?\"\n",
        "    ],\n",
        "    \"Legislation\": [\n",
        "        \"Â¿QuÃ© legislaciÃ³n protege o regula a {sci}?\",\n",
        "        \"Mencione leyes o normativas relacionadas con {sci}.\"\n",
        "    ],\n",
        "    \"Endemic\": [\n",
        "        \"Â¿{sci} es endÃ©mica de alguna regiÃ³n?\",\n",
        "        \"Indique las Ã¡reas donde {sci} es endÃ©mica.\"\n",
        "    ],\n",
        "    \"EnvironmentalEnvelope\": [\n",
        "        \"Â¿CuÃ¡l es el rango ambiental (precipitaciÃ³n, temperatura, etc.) donde vive {sci}?\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "\n",
        "# Campos del CSV que mapean directamente a los nombres Plinian usados\n",
        "CSV_TO_PLI = {\n",
        "    \"common_names\":            \"CommonNames\",\n",
        "    \"habitat\":                 \"Habitats\",\n",
        "    \"threat\":                  \"ThreatStatus\",\n",
        "    \"annual_cycles\":           \"AnnualCycles\",\n",
        "    \"phenology\":               \"AnnualCycles\",\n",
        "    \"behavior\":                \"Behavior\",\n",
        "    \"feeding\":                 \"Feeding\",\n",
        "    \"interaction\":             \"Interaction\",\n",
        "    \"life_cycle\":              \"LifeCycle\",\n",
        "    \"life_form\":               \"LifeForm\",\n",
        "    \"population_biology\":      \"PopulationBiology\",\n",
        "    \"reproduction\":            \"Reproduction\",\n",
        "    \"uses\":                    \"Uses\",\n",
        "    \"cr_distribution\":         \"Distribution\",\n",
        "    \"regional_distribution\":   \"Distribution\",\n",
        "    \"demography\":              \"DemographyAndThreat\",\n",
        "    \"synonyms\":                \"Synonyms\",\n",
        "    \"territory\":               \"Territory\",\n",
        "}\n",
        "\n",
        "\n",
        "# ------------------------ Limpieza bÃ¡sica -------------------------\n",
        "def clean_text(s: str) -> str:\n",
        "    return re.sub(r\"\\s+\", \" \", str(s)).strip()\n",
        "\n",
        "\n",
        "# ----------------- ConstrucciÃ³n de DataFrames --------------------\n",
        "def build_dataframes(csv_path: Path) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    df = pd.read_csv(csv_path, sep=\"|\")\n",
        "\n",
        "    df = (\n",
        "        df.assign(kingdom=lambda d: d[\"kingdom\"].str.title(),\n",
        "                  description=lambda d: d[\"description\"].apply(clean_text),\n",
        "                  description_type=lambda d: d[\"description_type\"].str.strip())\n",
        "          .drop_duplicates(subset=[\"taxon_record_id\", \"description_type\", \"description\"])\n",
        "    )\n",
        "\n",
        "    pivot = (\n",
        "    df.pivot_table(index=\"default_name\",\n",
        "                   columns=\"description_type\",\n",
        "                   values=\"description\",\n",
        "                   aggfunc=\" \".join)\n",
        "      .reset_index()\n",
        "    )\n",
        "    basics = (\n",
        "        df[[\"default_name\", \"kingdom\"]]\n",
        "        .drop_duplicates()\n",
        "    )\n",
        "    wide = basics.merge(pivot, on=\"default_name\", how=\"left\")\n",
        "\n",
        "    qa_rows = []\n",
        "    random.seed(SEED)\n",
        "\n",
        "    for _, row in wide.iterrows():\n",
        "        sci    = row[\"default_name\"]\n",
        "        kingdom= row[\"kingdom\"]\n",
        "\n",
        "        # 1. armar diccionario con todos los posibles reemplazos\n",
        "        subs = {\"sci\": sci, \"kingdom\": kingdom }\n",
        "        for csv_field in CSV_TO_PLI.keys():\n",
        "            subs[csv_field] = row.get(csv_field, \"\")\n",
        "\n",
        "        # 2. para cada campo Plinian presente, crear preguntas\n",
        "        for csv_field, plinian_field in CSV_TO_PLI.items():\n",
        "            if pd.isna(row.get(csv_field)):        # no hay dato\n",
        "                continue\n",
        "            texto_resp = row[csv_field]\n",
        "            for plantilla in TEMPLATES_PLI.get(plinian_field, []):\n",
        "                qa_rows.append({\n",
        "                    \"question\": plantilla.format(**subs).strip(),\n",
        "                    \"answer\": clean_text(texto_resp),\n",
        "                    \"plinian_field\": plinian_field,\n",
        "                    \"scientific_name\": sci,\n",
        "                    \"kingdom\": kingdom\n",
        "                })\n",
        "\n",
        "        # 3. aÃ±adir tambiÃ©n preguntas bÃ¡sicos siempre presentes\n",
        "        for plantilla in TEMPLATES_PLI[\"NomenclatureAndClassification\"]:\n",
        "            ans = sci if \"nombre cientÃ­fico\" in plantilla else kingdom\n",
        "            qa_rows.append({\n",
        "                \"question\": plantilla.format(**subs).strip(),\n",
        "                \"answer\": ans,\n",
        "                \"plinian_field\": \"NomenclatureAndClassification\",\n",
        "                \"scientific_name\": sci,\n",
        "                \"kingdom\": kingdom\n",
        "            })\n",
        "\n",
        "    docs_df = wide.rename(columns={\"taxon_record_id\": \"taxon_id\"})\n",
        "    qa_df   = pd.DataFrame(qa_rows)\n",
        "    return docs_df, qa_df\n",
        "\n",
        "\n",
        "# ----------------------- Encoder de embeddings -------------------\n",
        "encoder = SentenceTransformer(HF_MODEL)\n",
        "def embed(textos: List[str]) -> List[List[float]]:\n",
        "    return encoder.encode(textos, normalize_embeddings=True).tolist()\n",
        "\n",
        "\n",
        "# -------------------- Crear colecciÃ³n en Milvus ------------------\n",
        "connections.connect(host=MILVUS_HOST, port=MILVUS_PORT, alias=\"default\")\n",
        "\n",
        "if utility.has_collection(COLLECTION_NAME):\n",
        "    collection = Collection(COLLECTION_NAME)\n",
        "else:\n",
        "    schema = CollectionSchema([\n",
        "        FieldSchema(\"qa_id\", DataType.INT64, is_primary=True, auto_id=True),\n",
        "        FieldSchema(\"embedding\", DataType.FLOAT_VECTOR, dim=DIM),\n",
        "        FieldSchema(\"question\", DataType.VARCHAR, max_length=512),\n",
        "        FieldSchema(\"answer\",   DataType.VARCHAR, max_length=8192),\n",
        "        FieldSchema(\"plinian_field\", DataType.VARCHAR, max_length=64),\n",
        "        FieldSchema(\"scientific_name\", DataType.VARCHAR, max_length=128),\n",
        "        FieldSchema(\"kingdom\",         DataType.VARCHAR, max_length=32),\n",
        "    ], description=\"P-R etiquetados con elemento Plinian\")\n",
        "    collection = Collection(COLLECTION_NAME, schema, consistency_level=\"Strong\")\n",
        "    collection.create_index(\"embedding\", {\n",
        "        \"index_type\": \"IVF_FLAT\",\n",
        "        \"metric_type\": \"COSINE\",\n",
        "        \"params\": {\"nlist\": 2048}\n",
        "    })\n",
        "\n",
        "# --------------------------- Ingesta ------------------------------\n",
        "docs_df, qa_df = build_dataframes(CSV_PATH)\n",
        "\n",
        "print(f\"Especies leÃ­das:  {docs_df.shape[0]:,}\")\n",
        "print(f\"P-R generadas:   {qa_df.shape[0]:,}\")\n",
        "\n",
        "# InserciÃ³n por lotes\n",
        "batch_q, batch_a, batch_emb, batch_f, batch_sci, batch_king = ([] for _ in range(6))\n",
        "\n",
        "for _, fila in tqdm(qa_df.iterrows(), total=len(qa_df), desc=\"Insertando\"):\n",
        "    batch_q.append(fila[\"question\"])\n",
        "    batch_a.append(fila[\"answer\"])\n",
        "    batch_f.append(fila[\"plinian_field\"])\n",
        "    batch_sci.append(fila[\"scientific_name\"])\n",
        "    batch_king.append(fila[\"kingdom\"])\n",
        "\n",
        "    if len(batch_q) == BATCH:\n",
        "        collection.insert([\n",
        "            embed(batch_q), batch_q, batch_a,\n",
        "            batch_f, batch_sci, batch_king\n",
        "        ])\n",
        "        batch_q, batch_a, batch_f, batch_sci, batch_king = ([] for _ in range(5))\n",
        "\n",
        "# inserta lo restante\n",
        "if batch_q:\n",
        "    collection.insert([\n",
        "        embed(batch_q), batch_q, batch_a,\n",
        "        batch_f, batch_sci, batch_king\n",
        "    ])\n",
        "\n",
        "collection.flush()\n",
        "print(\"âœ…  Ingesta completada en Milvus\")\n"
      ],
      "metadata": {
        "id": "B1fvpdjyvyjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exploracion Metadatos InBio"
      ],
      "metadata": {
        "id": "u-M-lgWaZGPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Explora los metadatos presentes en reg_especies_INBiov5.csv\n",
        "-----------------------------------------------------------\n",
        "â€¢ pip install pandas\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "CSV_PATH = Path(\"reg_especies_INBiov5.csv\")\n",
        "SEP      = \"|\"                                # delimitador vertical\n",
        "\n",
        "# 1) Lee una pequeÃ±a porciÃ³n para ver las columnas\n",
        "preview = pd.read_csv(CSV_PATH, sep=SEP, nrows=5)\n",
        "print(\"Columnas del CSV:\")\n",
        "for c in preview.columns:\n",
        "    print(\"  â€¢\", c)\n",
        "\n",
        "types_series = pd.read_csv(\n",
        "    CSV_PATH,\n",
        "    sep=SEP,\n",
        "    usecols=[\"description_type\"]\n",
        ")[\"description_type\"].astype(str).str.strip()\n",
        "\n",
        "# 3) Obtiene lista Ãºnica y ordenada\n",
        "unique_types = sorted(types_series.unique())\n",
        "print(\"\\nMetadatos temÃ¡ticos (description_type) encontrados:\")\n",
        "for t in unique_types:\n",
        "    print(\"  â€¢\", t)\n",
        "\n",
        "# 4) Conteo de registros por tipo\n",
        "counts = types_series.value_counts().sort_values(ascending=False)\n",
        "print(\"\\nConteo de filas por metadato:\")\n",
        "for t, n in counts.items():\n",
        "    print(f\"  â€¢ {t:<35} {n:>6}\")\n"
      ],
      "metadata": {
        "id": "y9k1zeCGv61b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RAG"
      ],
      "metadata": {
        "id": "1uzxw97RY4nT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade sentence-transformers pymilvus transformers ipywidgets huggingface-hub --quiet"
      ],
      "metadata": {
        "id": "OGrf-gZhagrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q ipywidgets\n",
        "!jupyter nbextension enable --py widgetsnbextension\n",
        "!jupyter nbextension enable --py --sys-prefix widgetsnbextension"
      ],
      "metadata": {
        "id": "R6JVl2uZcDN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(\"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\")"
      ],
      "metadata": {
        "id": "NAKcqobgblVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0 Â· InstalaciÃ³n de dependencias â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "!pip install gradio==4.29.0 pymilvus sentence-transformers transformers accelerate bitsandbytes --quiet\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1 Â· Imports y ConfiguraciÃ³n â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import os, re, torch\n",
        "from typing import List, Dict\n",
        "\n",
        "import gradio as gr\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pymilvus import MilvusClient, Collection, connections\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TextIteratorStreamer\n",
        "\n",
        "# Milvus\n",
        "MILVUS_HOST = \"135.237.82.231\"\n",
        "MILVUS_PORT = \"19530\"\n",
        "COLLECTION  = \"inbio_plinian_qa\"\n",
        "VEC_FIELD   = \"embedding\"\n",
        "OUT_FIELDS  = [\"answer\", \"scientific_name\", \"plinian_field\"]\n",
        "\n",
        "# Modelos\n",
        "EMBED_MODEL = \"embaas/sentence-transformers-multilingual-e5-base\"   # 384 d\n",
        "LLM_ID      = \"NousResearch/Nous-Hermes-2-Mistral-7B-DPO\"          # abierto\n",
        "DEVICE      = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Busca top-k contextos; configurable desde la UI\n",
        "DEFAULT_K   = 5\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2 Â· Cargar embedder y LLM â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "embedder = SentenceTransformer(EMBED_MODEL, device=DEVICE)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(LLM_ID)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    LLM_ID,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16,\n",
        "    #load_in_4bit=True\n",
        ")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3 Â· Cliente Milvus â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(f\"ðŸ”¹ Conectando a Milvus {MILVUS_HOST}:{MILVUS_PORT}â€¦\")\n",
        "client = MilvusClient(uri=f\"tcp://{MILVUS_HOST}:{MILVUS_PORT}\")\n",
        "client.load_collection(COLLECTION)\n",
        "print(\"   ok\\n\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4 Â· Funciones auxiliares â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def detect_field(question:str)->str|None:\n",
        "    \"\"\"Clasificador placeholder (devuelve None = sin filtro).\"\"\"\n",
        "    q = question.lower()\n",
        "    if \"hÃ¡bitat\" in q: return \"Habitats\"\n",
        "    if \"amenaz\"  in q or \"uicn\" in q: return \"ThreatStatus\"\n",
        "    return None\n",
        "\n",
        "def build_prompt(question: str, hits: List[Dict]) -> str:\n",
        "    \"\"\"\n",
        "    Crea un prompt limpio para el LLM.\n",
        "    Cada hit es un dict que trae:\n",
        "        â€¢ hit['distance']          (float)\n",
        "        â€¢ hit['entity']['answer']  (str)\n",
        "        â€¢ hit['entity']['scientific_name']\n",
        "        â€¢ hit['entity']['plinian_field']\n",
        "    \"\"\"\n",
        "    # armamos bloques numerados con las 3-5 evidencias\n",
        "    bloques = []\n",
        "    for i, hit in enumerate(hits, 1):\n",
        "        ent = hit[\"entity\"]\n",
        "        dist = hit[\"distance\"]\n",
        "        breve = ent[\"answer\"]\n",
        "        bloques.append(\n",
        "            f\"[{i}] {ent['scientific_name']} Â· {ent['plinian_field']} \"\n",
        "            f\"(sim={1-dist:.3f}): {breve}\"\n",
        "        )\n",
        "\n",
        "    contexto = \"\\n\\n\".join(bloques)\n",
        "\n",
        "    prompt = (\n",
        "        \"Sistema: Eres un redactor experto en biodiversidad de Costa Rica. \"\n",
        "        \"Usa el contexto para responder en **un pÃ¡rrafos** bien redactados, \"\n",
        "        \"en espaÃ±ol, explicando el dato y aÃ±adiendo detalles relevantes del contexto. \"\n",
        "        f\"### CONTEXTO\\n{contexto}\\n\\n\"\n",
        "        f\"### PREGUNTA\\n{question}\\n\\n\"\n",
        "        \"### RESPUESTA (dos pÃ¡rrafos):\"\n",
        "    )\n",
        "    return prompt\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5 Â· FunciÃ³n principal para Gradio â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def rag_answer(msg: str, k: int = DEFAULT_K, temperatura: float = 0.0):\n",
        "    # 1) embedding\n",
        "    q_vec = embedder.encode([msg], normalize_embeddings=True)[0]\n",
        "\n",
        "    # 2) bÃºsqueda vectorial  (sin filtro por ahora)-> Por ahora no implementamos filtros, con milvus es muy facil y diverso\n",
        "    hits = client.search(\n",
        "        collection_name=COLLECTION,\n",
        "        data=[q_vec],\n",
        "        limit=k,\n",
        "        output_fields=OUT_FIELDS,\n",
        "        search_params={\"metric_type\": \"COSINE\", \"params\": {\"nprobe\": 10}}\n",
        "    )[0]\n",
        "    if not hits:\n",
        "        return \"No encontrÃ© informaciÃ³n suficiente para responder.\"\n",
        "\n",
        "    # 3) prompt\n",
        "    prompt = build_prompt(msg, hits)\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    # 4) generaciÃ³n bloqueante (mÃ¡s tokens para evitar corte)\n",
        "    out = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=256,\n",
        "        do_sample=temperatura > 0,\n",
        "        temperature=float(temperatura),\n",
        "        top_p=0.95,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    respuesta = tokenizer.decode(\n",
        "        out[0][inputs[\"input_ids\"].shape[-1]:],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "    return respuesta.strip()\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 6 Â· Construir interfaz Gradio â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"## ðŸŒ¿ **Biodiversidad Costa Rica â€“ RAG**\")\n",
        "\n",
        "    chat = gr.Chatbot(height=400)\n",
        "    with gr.Row():\n",
        "        txt = gr.Textbox(\n",
        "            scale=4,\n",
        "            placeholder=\"Pregunta sobre una especie, su hÃ¡bitat, amenazas, etc.\"\n",
        "        )\n",
        "        enviar = gr.Button(\"Enviar\", scale=1)\n",
        "\n",
        "    with gr.Row():\n",
        "        k_slider = gr.Slider(1,10,value=DEFAULT_K,step=1,label=\"Top-k documentos\")\n",
        "        temp = gr.Slider(0,1,value=0.0,step=0.05,label=\"Creatividad (temperature)\")\n",
        "\n",
        "    def user(user_message, history):\n",
        "        return \"\", history + [[user_message, None]]\n",
        "\n",
        "    def bot(history, k, temperatura):\n",
        "        user_message = history[-1][0]\n",
        "        respuesta = rag_answer(user_message, k=int(k), temperatura=float(temperatura))\n",
        "        history[-1][1] = respuesta\n",
        "        return history\n",
        "\n",
        "    txt.submit(user, [txt, chat], [txt, chat]).then(\n",
        "        bot, [chat, k_slider, temp], chat\n",
        "    )\n",
        "    enviar.click(user, [txt, chat], [txt, chat]).then(\n",
        "        bot, [chat, k_slider, temp], chat\n",
        "    )\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 7 Â· Lanzar servidor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "demo.launch(share=True, debug=True) #da una url publica\n"
      ],
      "metadata": {
        "id": "2Glnr5K-eqAm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}